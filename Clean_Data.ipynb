{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from scipy.stats import skew\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import power_transform\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import re\n",
    "\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('data/train.csv')\n",
    "test_raw = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "train = train[~((train['GrLivArea'] > 4000) & (train['SalePrice'] < 300000))]\n",
    "train = train[~((train['MasVnrArea'] > 1400) & (train['SalePrice'] < 300000))]\n",
    "train = train[~((train['LotFrontage'] > 300) & (train['SalePrice'] < 300000 ))]\n",
    "train = train[~((train['LotArea'] > 200000) & (train['SalePrice'] < 500000 ))]\n",
    "# train = train[~((train['YearBuilt'] < 1900) & (train['SalePrice'] > 400000))]\n",
    "train = train[~((train['OpenPorchSF'] > 500) & (train['SalePrice'] < 100000))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove SalePrice and Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_variable = np.log1p(train.SalePrice)\n",
    "id_ = test.Id\n",
    "train = train.loc[:,'MSSubClass':'SaleCondition']\n",
    "test = test.loc[:,'MSSubClass':'SaleCondition']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicoliearity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some features to avoid multicollinearity\n",
    "\n",
    "train.drop(['1stFlrSF','GarageArea', 'TotRmsAbvGrd'], axis=1, inplace=True)\n",
    "test.drop(['1stFlrSF','GarageArea','TotRmsAbvGrd'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewdness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feats = train.dtypes[train.dtypes != \"object\"].index\n",
    "\n",
    "\n",
    "skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "skewed_feats = skewed_feats[skewed_feats > .65]\n",
    "\n",
    "skewed_index = skewed_feats.index\n",
    "\n",
    "train[skewed_index] = boxcox1p(train[skewed_index], 0.1)\n",
    "test[skewed_index] = boxcox1p(test[skewed_index], 0.1)\n",
    "\n",
    "scale = StandardScaler()\n",
    "\n",
    "train[skewed_index] = scale.fit_transform(train[skewed_index])\n",
    "test[skewed_index] = scale.transform(test[skewed_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(train.mean())\n",
    "test = test.fillna(test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordnial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ords = []\n",
    "# for col in train:\n",
    "#     if 'Ex' in set(train[col]):\n",
    "#         ords.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ord_values = {'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for ordn in ords:\n",
    "#     train[ordn] = train[ordn].map(ord_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[ords] = train[ords].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = set(train.columns)\n",
    "test_cols = set(test.columns)\n",
    "\n",
    "test_drop =  list(test_cols - train_cols)\n",
    "test_unkonwn_dummies = list(train_cols - test_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dummies = test.reindex(columns=test_unkonwn_dummies, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([test, test_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range_bins = [(1800,1900), (1900,1910), (1910,1920), (1920,1930), (1930,1940), (1940,1950), (1950,1960), (1960,1970), (1970,1980), (1980,1990), (1990,2000), (2000,2011)]\n",
    "\n",
    "# bins = {r:x for (x,y) in range_bins for r in range(x,y)}\n",
    "\n",
    "# train['YearBuilt'] = train['YearBuilt'].map(bins)\n",
    "\n",
    "# test['YearBuilt'] = test['YearBuilt'].map(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['YearBuilt'] = train['YrSold'] - train['YearBuilt']\n",
    "# test['YearBuilt'] = test['YrSold'] - test['YearBuilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[['Age']] = train[['YearBuilt']].apply(lambda x: x.max() - x)\n",
    "# # train = train.drop('YearBuilt', axis=1)\n",
    "# test[['Age']] = test[['YearBuilt']].apply(lambda x: x.max() - x)\n",
    "# test = test.drop('YearBuilt', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garage Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test['GarageYrBlt'] = test['GarageYrBlt'].isna().apply(lambda x: int(not x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['GarageYrBlt'] = train['GarageYrBlt'].isna().apply(lambda x: int(not x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['GarageYrBlt'] = train['YrSold'] - train['GarageYrBlt']\n",
    "# test['GarageYrBlt'] = test['YrSold'] - test['GarageYrBlt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.drop('TotalBsmtSF', axis= 1, inplace=True)\n",
    "# test.drop('TotalBsmtSF', axis= 1, inplace=True)\n",
    "\n",
    "\n",
    "# train['TwoStory'] = train['2ndFlrSF'].isna().apply(lambda x: int(not x))\n",
    "# test['TwoStory'] = test['2ndFlrSF'].isna().apply(lambda x: int(not x))\n",
    "\n",
    "# train['SF'] = train['1stFlrSF'] + train['2ndFlrSF']\n",
    "# # train.drop(['1stFlrSF','2ndFlrSF'], axis= 1, inplace=True)\n",
    "\n",
    "# test['SF'] = test['1stFlrSF'] + test['2ndFlrSF']\n",
    "# test.drop(['1stFlrSF','2ndFlrSF'], axis= 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YearRemodAdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['YearRemodAdd']  = (train['YrSold'] - train['YearRemodAdd'])\n",
    "# test['YearRemodAdd']  = (test['YrSold'] - test['YearRemodAdd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_pickle('dump/train.pkl')\n",
    "test.to_pickle('dump/test.pkl')\n",
    "response_variable.to_pickle('dump/y_train.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
